1) Get the two directories with 100 helpful reviews under REVIEWS; and 100 unhelpful reviews under REVIEWS_UNHELPFUL. 
For this, I used similar commands to the ones from assignment 4 steps 1-3 
 
 1993  mkdir {ALL_REVIEWS,ALL_REVIEWS/HELPFUL,ALL_REVIEWS/UNHELPFUL}
 1994  cut -f 3,9 amazon_reviews_us_Books_v1_02.tsv | sort -nk2 | head -n 100 | awk '{print $1}' > reviewIDs.txt
 1995  input="reviewIDs.txt"; while read -r line; do awk -F"\t" -v "ID=$line" '$3 == ID' amazon_reviews_us_Books_v1_02.tsv > "ALL_REVIEWS/HELPFUL/$line.txt"; done < "$input"
 1996  for FILE in ALL_REVIEWS/HELPFUL/*.txt; do cut -f 14 "$FILE" | sed -e 's/ing[[:blank:]]/ /g;s/ed[[:blank:]]/ /g;s/[Ss][[:blank:]]/ /g' > "$FILE.temp" ; mv "$FILE.temp" "$FILE" ;  done
 1997  for FILE in ALL_REVIEWS/HELPFUL/*.txt; do sed -e 's/,//g;s/\.//g;s/\;//g;s/\x27//g;s/\!//g;s/\://g;s/\"//g;s/\?//g;s/\///g;s/\\//g;s/'\{'//g;s/'\}'//g;s/\[//g;s/\]//g;s/\|//g;s/\<//g;s/\>//g;s/\~//g;s/\`//g;s/@//g;s/\#//g;s/\$//g;s/%//g;s/\^//g;s/\&//g;s/\*//g;s/(//g;s/)//g;s/-//g;s/_//g;s/=//g;s/+//g' "$FILE" > "$FILE.temp" ; mv "$FILE.temp" "$FILE" ;  done
 1998  for FILE in ALL_REVIEWS/HELPFUL/*.txt; do sed -e 's/\<.\>//g;s/\<..\>//g' "$FILE" | sed 's/\<about\>//g;s/\<actually\>//g;s/\<almost\>//g;s/\<also\>//g;s/\<although\>//g;s/\<always\>//g;s/\<and\>//g;s/\<any\>//g;s/\<are\>//g;s/\<became\>//g;s/\<become\>//g;s/\<but\>//g;s/\<can\>//g;s/\<could\>//g;s/\<did\>//g;s/\<does\>//g;s/\<each\>//g;s/\<either\>//g;s/\<else\>//g;s/\<for\>//g;s/\<from\>//g;s/\<had\>//g;s/\<has\>//g;s/\<have\>//g;s/\<hence\>//g;s/\<how\>//g;s/\<its\>//g;s/\<may\>//g;s/\<maybe\>//g;s/\<might\>//g;s/\<mine\>//g;s/\<must\>//g;s/\<neither\>//g;s/\<nor\>//g;s/\<not\>//g;s/\<when\>//g;s/\<where\>//g;s/\<wherea\>//g;s/\<wherever\>//g;s/\<whenever\>//g;s/\<whether\>//g;s/\<which\>//g;s/\<while\>//g;s/\<who\>//g;s/\<whom\>//g;s/\<whoever\>//g;s/\<whose\>//g;s/\<why\>//g;s/\<will\>//g;s/\<with\>//g;s/\<within\>//g;s/\<without\>//g;s/\<would\>//g;s/\<yes\>//g;s/\<yet\>//g;s/\<you\>//g;s/\<your\>//g;s/\<the\>//g;s/\<thi\>//g' > "$FILE.temp" ; mv "$FILE.temp" "$FILE" ; done
 1999  cut -f 3,9 amazon_reviews_us_Books_v1_02.tsv | sort -nk2 | tail -n 100 | awk '{print $1}' > reviewIDs.txt
 2000  input="reviewIDs.txt"; while read -r line; do awk -F"\t" -v "ID=$line" '$3 == ID' amazon_reviews_us_Books_v1_02.tsv > "ALL_REVIEWS/UNHELPFUL/$line.txt"; done < "$input"
 2001  for FILE in ALL_REVIEWS/UNHELPFUL/*.txt; do cut -f 14 "$FILE" | sed -e 's/ing[[:blank:]]/ /g;s/ed[[:blank:]]/ /g;s/[Ss][[:blank:]]/ /g' > "$FILE.temp" ; mv "$FILE.temp" "$FILE" ;  done
 2002  for FILE in ALL_REVIEWS/UNHELPFUL/*.txt; do sed -e 's/,//g;s/\.//g;s/\;//g;s/\x27//g;s/\!//g;s/\://g;s/\"//g;s/\?//g;s/\///g;s/\\//g;s/'\{'//g;s/'\}'//g;s/\[//g;s/\]//g;s/\|//g;s/\<//g;s/\>//g;s/\~//g;s/\`//g;s/@//g;s/\#//g;s/\$//g;s/%//g;s/\^//g;s/\&//g;s/\*//g;s/(//g;s/)//g;s/-//g;s/_//g;s/=//g;s/+//g' "$FILE" > "$FILE.temp" ; mv "$FILE.temp" "$FILE" ;  done
 2003  for FILE in ALL_REVIEWS/UNHELPFUL/*.txt; do sed -e 's/\<.\>//g;s/\<..\>//g' "$FILE" | sed 's/\<about\>//g;s/\<actually\>//g;s/\<almost\>//g;s/\<also\>//g;s/\<although\>//g;s/\<always\>//g;s/\<and\>//g;s/\<any\>//g;s/\<are\>//g;s/\<became\>//g;s/\<become\>//g;s/\<but\>//g;s/\<can\>//g;s/\<could\>//g;s/\<did\>//g;s/\<does\>//g;s/\<each\>//g;s/\<either\>//g;s/\<else\>//g;s/\<for\>//g;s/\<from\>//g;s/\<had\>//g;s/\<has\>//g;s/\<have\>//g;s/\<hence\>//g;s/\<how\>//g;s/\<its\>//g;s/\<may\>//g;s/\<maybe\>//g;s/\<might\>//g;s/\<mine\>//g;s/\<must\>//g;s/\<neither\>//g;s/\<nor\>//g;s/\<not\>//g;s/\<when\>//g;s/\<where\>//g;s/\<wherea\>//g;s/\<wherever\>//g;s/\<whenever\>//g;s/\<whether\>//g;s/\<which\>//g;s/\<while\>//g;s/\<who\>//g;s/\<whom\>//g;s/\<whoever\>//g;s/\<whose\>//g;s/\<why\>//g;s/\<will\>//g;s/\<with\>//g;s/\<within\>//g;s/\<without\>//g;s/\<would\>//g;s/\<yes\>//g;s/\<yet\>//g;s/\<you\>//g;s/\<your\>//g;s/\<the\>//g;s/\<thi\>//g' > "$FILE.temp" ; mv "$FILE.temp" "$FILE" ; done

2) Install and Run Weka on the server as follows. 
You will probably need to update your CLASSPATH. 
Running Weka usually requires adding weka.jar to the CLASSPATH variable of the hosting machine. 
On Linux and Mac machines, you can also add it to the .bash_profile or .bashrc so you don't have to update CLASSPATH every time you login.
 You can update CLASSPATH with the following lines: 

wget https://prdownloads.sourceforge.net/weka/weka-3-8-5-azul-zulu-linux.zip
unzip weka-3-8-5-azul-zulu-linux.zip
export CLASSPATH=$CLASSPATH:`pwd`/weka.jar:`pwd`/libsvm.jar
./weka-3-8-5/weka.sh

NOTE: During the scripting of the console and command log this installation was already completed, so I represented it with the command below.

2004  export CLASSPATH=$CLASSPATH:`pwd`/weka.jar:`pwd`/libsvm.jar

3) Convert the helpful and unhelpful review files into a single .arff file

 2005  java weka.core.converters.TextDirectoryLoader -dir ALL_REVIEWS > all_reviews.arff
 
 4) Check arrf file 

 2006  nano all_reviews.arff
 
 5) Convert arff to training data for model

 2007  java -Xmx1024m weka.filters.unsupervised.attribute.StringToWordVector  -i all_reviews.arff -o all_reviews_training.arff -M 2

6) Check and describe training file
Looking into the training file, I can see all of the words from the cleaned up review as "attributes"
Each word is desbribed as a numeric attribute on its own line
I also see a header file that describes the relation that the arff file describes
Weka describes the file as WordTokenizer with a very long list of specifications from how it turns words into WordTokens

 2008  nano all_reviews_training.arff
 
 7) Run any Weka classifier you like. 
Instead of the default ClassificationViaRegression , I used the AdaBoostM1 classifier.
This classifier is known for its efficiency, with some loss of accuracy compared to ClassificationViaRegression

 2009  java -Xmx1024m  weka.classifiers.meta.AdaBoostM1 -W weka.classifiers.trees.DecisionStump   -t  all_reviews_training.arff -d all_reviews_training.model -c 1
 
 8) Script to serialize file to machine learned model process from above
Two parameters for script: absolute path of weka installation, and absolute path of files to use in ML process
NOTE: The nano command here doesn't show what the script is, but script is part of github repo.

 2010  rm text_binary_classify.sh
 2011  nano text_binary_classify.sh
 2012  chmod +x text_binary_classify.sh
 
 9) Now that you have a shell script that should automate your analysis, repeat the ML training for two cases:
- using in training files that contain just the amazon review_body text
- using the files you produced in assignment #4, which contain both the amazon review_body text and integrated tweets.
 Although I was unable to get assignment 4 parallel command to execute, I was able to do this step with a serialized execution of commonTweets bash script.
 
  PART 1)
 2013  ./text_binary_classify.sh ./weka-3-8-5 ./ALL_REVIEWS
  PART 2) (setup and execution)
 2014  mkdir {REVIEWS_WITH_TWEETS,REVIEWS_WITH_TWEETS/HELPFUL,REVIEWS_WITH_TWEETS/UNHELPFUL}
 2015  cp ALL_REVIEWS/HELPFUL/* REVIEWS_WITH_TWEETS/HELPFUL/
 2016  ls REVIEWS_WITH_TWEETS/HELPFUL
 2017  cp ALL_REVIEWS/UNHELPFUL/* REVIEWS_WITH_TWEETS/UNHELPFUL/
 2018  time for FILE in REVIEWS_WITH_TWEETS/HELPFUL/*.txt; do ./commonTweets.sh "$FILE" training.1600000.processed.noemoticon.csv ; done
 2019  time for FILE in REVIEWS_WITH_TWEETS/UNHELPFUL/*.txt; do ./commonTweets.sh "$FILE" training.1600000.processed.noemoticon.csv ; done
 2020  ./text_binary_classify.sh ./weka-3-8-5 ./REVIEWS_WITH_TWEETS
 
 10)
The AdaBoostM1 based classification was able to differenciate the reviews in a way that most helpful reviews were seen in the helpful category, and visa versa with the unhelpful reviews. 
This was entirely done by looking at the reviews themselves, and feeding them into the weka classifier. The end result is 82% accuracy for unhelpful reviews, and 84% for helpful reviews.
Looking at the version of the files with tweets, the accuracy is actually worse than this (with the same AdaBoostM1 metric).
Only 80% of unhelpful reviews are found as unhelpful, and 82% of helpful reviews are found helpful.
More accuracy is not obtained in this case considering the lack of context from any given tweet.
There is an unreliability to random tweets as a way to measure amazon review helpfulness. 
 
 2021  history > cmds.log
